{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import Utilities.Weather as uw\n",
    "import Utilities.SnD as us\n",
    "import APIs.QuickStats as qs\n",
    "\n",
    "import warnings # supress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region declarations\n",
    "corn_states=['IA','IL','IN','OH','MO','MN','SD','NE']\n",
    "years=range(1985,2023)\n",
    "\n",
    "# Select the Weather Stations\n",
    "df_w_sel = uw.get_w_sel_df()\n",
    "df_w_sel = df_w_sel[df_w_sel[uw.WS_COUNTRY_ALPHA] == 'USA']\n",
    "\n",
    "# Build the Weather DF\n",
    "w_vars = [uw.WV_PREC, uw.WV_TEMP_MAX]\n",
    "in_files = uw.WS_UNIT_ALPHA\n",
    "out_cols = uw.WS_UNIT_ALPHA\n",
    "w_df_all = uw.build_w_df_all(df_w_sel, w_vars, in_files, out_cols)\n",
    "\n",
    "# Build the Weights\n",
    "weights = us.get_USA_prod_weights('CORN', 'STATE', years, corn_states)\n",
    "\n",
    "# Weighted DataFrame\n",
    "w_w_df_all = uw.weighted_w_df_all(w_df_all, weights, output_column='USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATES: Pollination SDD (Dates are silking 50% -15 and +15 days)\n",
    "silking_df=qs.get_QS_progress(progress_var='silking',years=years,cols_subset=['week_ending','Value'])\n",
    "\n",
    "silk_50_pct=us.dates_from_progress(silking_df, sel_percentage=50)\n",
    "silk_50_pct_CUR_YEAR=pd.Series([dt(uw.CUR_YEAR,d.month,d.day) for d in silk_50_pct['date']]) # Adding current estimate for silking dates\n",
    "silk_50_pct.loc[uw.CUR_YEAR]= np.mean(silk_50_pct_CUR_YEAR)\n",
    "\n",
    "start=silk_50_pct['date']+pd.DateOffset(-15)\n",
    "end=silk_50_pct['date']+pd.DateOffset(15)\n",
    "pollination_dates=pd.DataFrame({'start':start,'end':end})\n",
    "\n",
    "\n",
    "# DATES: Regular SDD (Dates are 20 Jun - 15 Sep)\n",
    "start=[dt(y,6,20) for y in silk_50_pct.index]\n",
    "end=[dt(y,9,25) for y in silk_50_pct.index]\n",
    "regular_dates=pd.DataFrame({'start':start,'end':end},index=silk_50_pct.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USA_TempSDD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>10.520536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>15.791750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>61.975260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>179.854116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>21.208432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>77.205579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>61.665397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>6.130904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>15.367580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>19.579622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>62.880336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>19.687865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>8.875387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>40.697484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>11.074297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>16.572747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>33.471519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>75.719337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>80.325757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>1.080487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>62.450375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>21.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>61.392928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1.835931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>18.342710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>50.989552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>24.216747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>109.899912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>61.780354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.991317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>24.039929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>22.276680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>4.498685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>16.102992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>19.265559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>28.701590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>25.451745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>35.348486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      USA_TempSDD\n",
       "1985    10.520536\n",
       "1986    15.791750\n",
       "1987    61.975260\n",
       "1988   179.854116\n",
       "1989    21.208432\n",
       "1990    77.205579\n",
       "1991    61.665397\n",
       "1992     6.130904\n",
       "1993    15.367580\n",
       "1994    19.579622\n",
       "1995    62.880336\n",
       "1996    19.687865\n",
       "1997     8.875387\n",
       "1998    40.697484\n",
       "1999    11.074297\n",
       "2000    16.572747\n",
       "2001    33.471519\n",
       "2002    75.719337\n",
       "2003    80.325757\n",
       "2004     1.080487\n",
       "2005    62.450375\n",
       "2006    21.999407\n",
       "2007    61.392928\n",
       "2008     1.835931\n",
       "2009    18.342710\n",
       "2010    50.989552\n",
       "2011    24.216747\n",
       "2012   109.899912\n",
       "2013    61.780354\n",
       "2014     0.991317\n",
       "2015    24.039929\n",
       "2016    22.276680\n",
       "2017     4.498685\n",
       "2018    16.102992\n",
       "2019    19.265559\n",
       "2020    28.701590\n",
       "2021    25.451745\n",
       "2022    35.348486"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day=dt(2022,6,10)\n",
    "\n",
    "sel_ext_df=w_w_df_all[uw.WD_H_GFS].copy()\n",
    "\n",
    "sel_ext_df['USA_TempSDD']=sel_ext_df['USA_TempMax']\n",
    "mask=sel_ext_df['USA_TempSDD']>30.0\n",
    "sel_ext_df['USA_TempSDD'][mask]=sel_ext_df['USA_TempSDD'][mask]-30.0\n",
    "sel_ext_df['USA_TempSDD'][~mask]=0\n",
    "\n",
    "w_w_df_ext = uw.extend_with_seasonal_df(w_df, modes=[uw.EXT_MEAN])\n",
    "w_w_df_ext\n",
    "\n",
    "M_pollination_sdd = uw.extract_w_windows(w_w_df_ext[['USA_TempSDD']], pollination_dates)\n",
    "M_pollination_sdd*9/5\n",
    "\n",
    "M_regular_sdd = uw.extract_w_windows(w_w_df_ext[['USA_TempSDD']], regular_dates)\n",
    "M_regular_sdd*9/5-M_pollination_sdd*9/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:\n",
      "SD_TempAvg_gfs.csv (15CjUUaTF472P1BQEUNJO_nhjtP_Ac9eg)\n",
      "SD_TempMin_gfs.csv (14WYBt8JUXgTGpsczpiCTHlumUnSWithy)\n",
      "SD_TempMax_gfs.csv (10AIb9jeltMrBDk0KOMPeyrpt5q5Zm5Up)\n",
      "SD_Prec_gfs.csv (1202k-tHWue4xACcgsigklEjkm3ndaQbT)\n",
      "OH_TempAvg_gfs.csv (13bYHWIhaIWeqMzq57qx4DOO3bp4VSoij)\n",
      "OH_TempMin_gfs.csv (116q7VJT5GrXy1s3Bil_PTEtOHZEvzBcl)\n",
      "OH_TempMax_gfs.csv (1-Dr-lK0jHDiQWlKXuwKPJ3I36CaxebL6)\n",
      "OH_Prec_gfs.csv (11gON3bke-UMJNi-0hBfbeQKtRhTcVadB)\n",
      "NE_TempAvg_gfs.csv (13dB922LFFDUQdUZGWpgnvPqjnU9SQIPk)\n",
      "NE_TempMin_gfs.csv (122O1IMp4fiFosbrK_kd2giBMq-9OucwJ)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "# SCOPES = ['https://www.googleapis.com/auth/drive.metadata.readonly']\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "creds = None\n",
    "# The file token.json stores the user's access and refresh tokens, and is\n",
    "# created automatically when the authorization flow completes for the first\n",
    "# time.\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "# If there are no (valid) credentials available, let the user log in.\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            'credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    # Save the credentials for the next run\n",
    "    with open('token.json', 'w') as token:\n",
    "        token.write(creds.to_json())\n",
    "\n",
    "try:\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    # Call the Drive v3 API\n",
    "    results = service.files().list(\n",
    "        pageSize=10, fields=\"nextPageToken, files(id, name)\").execute()\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    if not items:\n",
    "        print('No files found.')\n",
    "        \n",
    "    print('Files:')\n",
    "    for item in items:\n",
    "        print(u'{0} ({1})'.format(item['name'], item['id']))\n",
    "except HttpError as error:\n",
    "    # TODO(developer) - Handle errors from drive API.\n",
    "    print(f'An error occurred: {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Utilities.Weather as uw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=uw.get_w_sel_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amuIds',\n",
       " 'idBlock',\n",
       " 'country_alpha',\n",
       " 'country_code',\n",
       " 'unit_name',\n",
       " 'unit_alpha',\n",
       " 'unit_code',\n",
       " 'state_name',\n",
       " 'state_alpha',\n",
       " 'state_code',\n",
       " 'Prec',\n",
       " 'TempAvg',\n",
       " 'TempMin',\n",
       " 'TempMax',\n",
       " 'TempSurf',\n",
       " 'Soil',\n",
       " 'Humi',\n",
       " 'VVI']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=list(test.columns)\n",
    "cols.remove('country_name')\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '1-7mnO-RX9GiCWsLqF5ngo0a4Z5o4je3W'\n",
    "path = 'https://drive.google.com/uc?export=download&id='+file_id\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52135293/google-drive-api-the-user-has-not-granted-the-app-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.streamlit.io/t/google-drive-csv-file-link-to-pandas-dataframe/8057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developers.google.com/drive/api/v2/reference/files/get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apiclient import errors\n",
    "from apiclient import http\n",
    "# ...\n",
    "\n",
    "def print_file_metadata(service, file_id):\n",
    "  \"\"\"Print a file's metadata.\n",
    "\n",
    "  Args:\n",
    "    service: Drive API service instance.\n",
    "    file_id: ID of the file to print metadata for.\n",
    "  \"\"\"\n",
    "\n",
    "  return(service.files().get(fileId=file_id).execute())\n",
    "\n",
    "\n",
    "def print_file_content(service, file_id):\n",
    "  \"\"\"Print a file's content.\n",
    "\n",
    "  Args:\n",
    "    service: Drive API service instance.\n",
    "    file_id: ID of the file.\n",
    "\n",
    "  Returns:\n",
    "    File's content if successful, None otherwise.\n",
    "  \"\"\"\n",
    "  # print (service.files().get_media(fileId=file_id).execute())\n",
    "  return service.files().get_media(fileId=file_id).execute()\n",
    "\n",
    "\n",
    "def download_file(service, file_id, local_fd):\n",
    "  \"\"\"Download a Drive file's content to the local filesystem.\n",
    "\n",
    "  Args:\n",
    "    service: Drive API Service instance.\n",
    "    file_id: ID of the Drive file that will downloaded.\n",
    "    local_fd: io.Base or file object, the stream that the Drive file's\n",
    "        contents will be written to.\n",
    "  \"\"\"\n",
    "  request = service.files().get_media(fileId=file_id)\n",
    "  media_request = http.MediaIoBaseDownload(local_fd, request)\n",
    "\n",
    "  while True:\n",
    "    download_progress, done = media_request.next_chunk()\n",
    "\n",
    "    if download_progress:\n",
    "      print ('Download Progress: %d%%' % int(download_progress.progress() * 100))\n",
    "    if done:\n",
    "      print ('Download Complete')\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id='1dWZkKoknSvOS2PKkxGmIyh5HtYYd1HZ3'\n",
    "\n",
    "test=pd.read_csv(print_file_content(service,file_id))\n",
    "\n",
    "# f = open(\"test.csv\", \"r\", encoding=\"utf-8\")\n",
    "\n",
    "# download_file(service,file_id, test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utilities.Weather as uw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amuIds</th>\n",
       "      <th>idBlock</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_alpha</th>\n",
       "      <th>country_code</th>\n",
       "      <th>unit_name</th>\n",
       "      <th>unit_alpha</th>\n",
       "      <th>unit_code</th>\n",
       "      <th>state_name</th>\n",
       "      <th>state_alpha</th>\n",
       "      <th>state_code</th>\n",
       "      <th>Prec</th>\n",
       "      <th>TempAvg</th>\n",
       "      <th>TempMin</th>\n",
       "      <th>TempMax</th>\n",
       "      <th>TempSurf</th>\n",
       "      <th>Soil</th>\n",
       "      <th>Humi</th>\n",
       "      <th>VVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018108</td>\n",
       "      <td>129</td>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>IA</td>\n",
       "      <td>wip</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>IA</td>\n",
       "      <td>wip</td>\n",
       "      <td>y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018106</td>\n",
       "      <td>129</td>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>IL</td>\n",
       "      <td>wip</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>IL</td>\n",
       "      <td>wip</td>\n",
       "      <td>y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amuIds idBlock   country_name country_alpha country_code unit_name  \\\n",
       "0  1018108     129  United States           USA          840      Iowa   \n",
       "1  1018106     129  United States           USA          840  Illinois   \n",
       "\n",
       "  unit_alpha unit_code state_name state_alpha state_code Prec TempAvg TempMin  \\\n",
       "0         IA       wip       Iowa          IA        wip    y     NaN       y   \n",
       "1         IL       wip   Illinois          IL        wip    y     NaN       y   \n",
       "\n",
       "  TempMax TempSurf Soil Humi  VVI  \n",
       "0       y      NaN  NaN  NaN  NaN  \n",
       "1       y      NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_states=['IL','IA']\n",
    "sel_df=uw.get_w_sel_df()\n",
    "\n",
    "if True:\n",
    "    test=sel_df[sel_df['state_alpha'].isin(sel_states)]\n",
    "else:\n",
    "    sel_df=sel_df.set_index('state_alpha',drop=False)\n",
    "    test=sel_df.loc[sel_states]\n",
    "\n",
    "\n",
    "test\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9960baf88259386db57c734c8604c8e4ab789688672644b3cf73fda24b112c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
